# ğŸš• iFood NYC Taxi Agency

A data engineering and analytics project focused on processing, transforming, and analyzing **New York City Taxi** data using modern data-stack tools such as **AWS Glue, Athena, Iceberg, Terraform, and Python**.

This repository demonstrates an end-to-end data platform approach â€” from ingestion and ETL to analytics and infrastructure provisioning â€” inspired by real-world delivery and mobility use cases.

---

## ğŸ“Œ Overview

The **iFood NYC Taxi Agency** project simulates how a data team could ingest large-scale public mobility datasets and make them analytics-ready for business insights.

The project covers:

- Programmatic ingestion of NYC Taxi data
- ETL pipelines using AWS Glue
- Table formats with Apache Iceberg
- Querying with Amazon Athena
- Infrastructure provisioning with Terraform
- Exploratory data analysis using Jupyter notebooks

Although the name references *iFood*, this is a **technical case study** and learning project â€” not an official iFood system.

---

## âœ¨ Features

- ğŸ“¥ **Data ingestion** from public APIs and datasets
- ğŸ”„ **ETL pipelines** orchestrated with AWS Glue
- ğŸ§Š **Apache Iceberg tables** for scalable analytics
- ğŸ§  **Analytical queries** using Amazon Athena
- ğŸ“Š **Exploratory analysis** via Jupyter notebooks
- â˜ï¸ **Infrastructure as Code** using Terraform
- ğŸ§° Modular, reusable Python codebase

---

## ğŸ“ Project Structure

```
ifood-nyc-taxi-agency/
â”œâ”€â”€ analysis/                    # Jupyter notebooks with exploratory analysis
â”‚   â”œâ”€â”€ average_passager_count.ipynb
â”‚   â””â”€â”€ average_total_amount.ipynb
â”‚
â”œâ”€â”€ src/                         # Application source code
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ ifood/
â”‚       â”œâ”€â”€ main.py              # Project entry point
â”‚       â”œâ”€â”€ vars.py              # Global configuration & constants
â”‚       â”‚
â”‚       â”œâ”€â”€ api/                 # Data ingestion layer
â”‚       â”‚   â””â”€â”€ fetch_data.py
â”‚       â”‚
â”‚       â”œâ”€â”€ etl/                 # ETL & Glue jobs
â”‚       â”‚   â”œâ”€â”€ glue_setup.py
â”‚       â”‚   â””â”€â”€ etl_process.py
â”‚       â”‚
â”‚       â””â”€â”€ aws/                 # AWS integrations
â”‚           â”œâ”€â”€ credentials.py
â”‚           â”œâ”€â”€ s3_bucket.py
â”‚           â”œâ”€â”€ glue_catalog.py
â”‚           â”œâ”€â”€ glue_iceberg_job.py
â”‚           â””â”€â”€ athena_queries.py
â”‚
â”œâ”€â”€ terraform/                   # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ output.tf
â”‚   â””â”€â”€ terraform_admin_policy.txt
â”‚
â”œâ”€â”€ setup.sh                     # Local environment bootstrap
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ” AWS Account & IAM Prerequisites (Required)

> âš ï¸ **Important**: This project assumes an AWS identity is **already configured and authenticated** before running any setup scripts or Terraform commands.

Before running `setup.sh`, `setup.py`, or any Terraform command, you **must** have a working AWS user or role with valid credentials.

### âœ… Required AWS Setup

You need **one AWS identity** (user or role) that:

- Can authenticate successfully with **AWS STS**
- Has permissions to create and manage:
  - IAM users and roles
  - S3 buckets and objects
  - AWS Glue resources (catalogs, crawlers, jobs)
  - Amazon Athena resources

This identity is referred to as the **bootstrap / admin identity**.

> ğŸ”‘ The bootstrap identity is used **only to provision infrastructure**.  
> It is **not** the same IAM user that runs Glue jobs or data pipelines.

---

### ğŸ” Verify AWS Credentials (Mandatory Check)

```bash
aws sts get-caller-identity
```

You **must** see a valid AWS Account ID and ARN.

---

### ğŸ‘¤ IAM User Separation (Critical)

| Purpose | Identity |
|------|--------|
| Run Terraform & setup scripts | **Admin / bootstrap user or role** |
| Run Glue, Athena, ETL pipelines | `terraform-aws` (created by Terraform) |

ğŸš« **Do NOT** run Terraform using the same IAM user that Terraform creates (`terraform-aws`).

---

### ğŸ§° AWS CLI Profile (Recommended)

```bash
aws configure --profile default
export AWS_PROFILE=default
```

---

### ğŸ›‘ Common Authentication Pitfalls

- âŒ Using expired temporary credentials (`AWS_SESSION_TOKEN`)
- âŒ Mixing AWS SSO credentials with static access keys
- âŒ Running Terraform as the same IAM user it manages
- âŒ Missing `sts:GetCallerIdentity` permission

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.9+**
- **pip**
- **AWS CLI** (authenticated)
- **Terraform** (>= 1.3 recommended)

Optional but recommended:

- Docker
- Jupyter Notebook

---

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/leooliveira135/ifood-nyc-taxi-agency.git
cd ifood-nyc-taxi-agency
```

2. **Run the setup script**

```bash
bash setup.sh
```

3. **Install Python dependencies**

```bash
pip install -r src/requirements.txt
```

---

## â–¶ï¸ Usage

### Run the ETL pipeline

```bash
python src/ifood/main.py
```

This will:

- Fetch NYC Taxi data
- Upload data to S3
- Create Glue catalogs
- Run Iceberg-based ETL jobs

---

## ğŸ“Š Analysis

The `analysis/` folder contains Jupyter notebooks focused on business insights such as:

- Average passenger count per trip
- Average total amount by trip

### ğŸ”§ Required Setup for Notebooks

Before running any notebook, you **must install the project in editable mode** so that the notebooks can correctly import the internal `ifood` Python package.

Run the following command **from the project root**:

```bash
pip install -e .
```

#### Why this is required

- The notebooks import modules from `src/ifood/`
- Without editable installation, Python will raise errors such as:
  - `ModuleNotFoundError: No module named 'ifood'`
- `pip install -e .` tells Python to treat the project as a local package while allowing live code changes

### â–¶ï¸ Running the notebooks

After installing the package:

```bash
jupyter notebook
```

Then open any notebook inside the `analysis/` directory.

> âš ï¸ These notebooks assume that:
> - The ETL pipeline has already been executed
> - Data is available in Athena / Iceberg tables

---

## ğŸ§ª Testing

This project does not yet include a full automated test suite.

Recommended next steps:

- Add unit tests for ETL logic
- Mock AWS services using `moto`
- Validate schema evolution for Iceberg tables

---

## ğŸ›£ Roadmap

- [x] Initial project structure
- [x] Basic ETL pipeline
- [x] Athena analytics
- [ ] Add data quality checks
- [ ] Add orchestration (Airflow / Step Functions)
- [ ] CI/CD pipeline

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Open a Pull Request

Please keep commits small and well-documented.

---

## ğŸ›¡ License

This project is licensed under the **GPL-3.0 License**.

See the [LICENSE](./LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- NYC Taxi & Limousine Commission (public datasets)
- Apache Iceberg community
- AWS Glue & Athena documentation
